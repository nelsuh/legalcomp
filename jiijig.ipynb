{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. Data written to output.jsonl.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import json\n",
    "import re\n",
    "\n",
    "def setup_driver():\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    chrome_options.add_argument('--no-sandbox')\n",
    "    chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "    return driver\n",
    "\n",
    "\n",
    "\n",
    "def fetch_texts(url):\n",
    "    driver = setup_driver()\n",
    "    texts_mon = \"\"\n",
    "    texts_eng = \"\"\n",
    "    title = \"\"\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Extract title using the new method\n",
    "        title_tag = soup.find('p', style=lambda value: value and 'padding-left:' in value)\n",
    "        title = title_tag.get_text(strip=True) if title_tag else \"Title not found\"\n",
    "\n",
    "        # Fetch Mongolian text\n",
    "        element_mon = soup.find('div', class_='maincontenter w-100 pull-left')\n",
    "        if element_mon:\n",
    "            texts_mon = element_mon.get_text(strip=True).replace(\"Хэвлэх\", \"\")\n",
    "\n",
    "        # Navigate to the page with Selenium to check for the active tab\n",
    "        driver.get(url)\n",
    "        try:\n",
    "            WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'a[href=\"#active-tab-11\"]')))\n",
    "            # Fetch English text\n",
    "            element_eng = soup.find('div', class_='w-100 pull-left --nomigration')\n",
    "            if element_eng:\n",
    "                texts_eng = element_eng.get_text(strip=True)\n",
    "        except:\n",
    "            # Handle cases where the active tab 11 does not exist\n",
    "            texts_eng = \"not.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {url}: {str(e)}\")\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "    return {'url': url, 'title': title, 'mon': texts_mon, 'eng': texts_eng}\n",
    "\n",
    "# List of URLs to process\n",
    "\n",
    "# Use ThreadPoolExecutor to handle multiple URLs in parallel\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    results = list(executor.map(fetch_texts, all_links))\n",
    "\n",
    "# Write results to JSONL file\n",
    "with open('output3.jsonl', 'w', encoding='utf-8') as f:\n",
    "    for result in results:\n",
    "        json_line = json.dumps({\"title\": result['title'], \"mon\": result['mon'], \"eng\": result['eng']}, ensure_ascii=False)\n",
    "        f.write(json_line + '\\n')\n",
    "\n",
    "print(\"Processing complete. Data written to output.jsonl.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# title zow shaah bha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Setup Chrome with Selenium using Service\n",
    "service = Service(executable_path=ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "num_pages = 45\n",
    "base_url = 'https://legalinfo.mn/mn/law?page=law&cate=27&active=1&sort=title&page='\n",
    "\n",
    "all_links = []\n",
    "all_titles = []\n",
    "\n",
    "for page_num in range(1, num_pages+1):\n",
    "    url = base_url + str(page_num)\n",
    "    driver.get(url)\n",
    "    wait = WebDriverWait(driver, 10) \n",
    "\n",
    "    try:\n",
    "        # Wait for the 'shine-huuli-main' div to be loaded\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \"div.shine-huuli-main\"))\n",
    "        )\n",
    "        time.sleep(1)\n",
    "        # Extract information\n",
    "        html_source = driver.page_source\n",
    "        soup = BeautifulSoup(html_source, 'html.parser')\n",
    "\n",
    "        # Find the container with the specified class\n",
    "        container = soup.find(\"div\", {\"class\": \"shine-huuli-main\"})\n",
    "        if container:\n",
    "            # Extract links and titles that have the specific class \"act-name\"\n",
    "            acts = container.select('a.act-name')\n",
    "            links = [a['href'] for a in acts]\n",
    "            titles = [a.text.strip() for a in acts]\n",
    "            all_links.extend(links)\n",
    "            all_titles.extend(titles)\n",
    "            print(f\"Links and Titles from Page {page_num}: {list(zip(links, titles))}\")\n",
    "        else:\n",
    "            print(\"No container with the specified class found.\")\n",
    "\n",
    "    finally:\n",
    "        # Ensure the browser is closed even if an error occurs\n",
    "        print(\"End of Page\", page_num)\n",
    "        time.sleep(1)\n",
    "\n",
    "print(\"All Links:\", all_links)\n",
    "print(\"All Titles:\", all_titles)\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import json\n",
    "import re\n",
    "\n",
    "def setup_driver():\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    chrome_options.add_argument('--no-sandbox')\n",
    "    chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "    return driver\n",
    "\n",
    "\n",
    "\n",
    "def fetch_texts(url):\n",
    "    driver = setup_driver()\n",
    "    texts_mon = \"\"\n",
    "    texts_eng = \"\"\n",
    "    title = \"\"\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Extract title using the new method\n",
    "        \n",
    "        for title in all_titles:\n",
    "            return title\n",
    "\n",
    "        # Fetch Mongolian text\n",
    "        element_mon = soup.find('div', class_='maincontenter w-100 pull-left')\n",
    "        if element_mon:\n",
    "            texts_mon = element_mon.get_text(strip=True).replace(\"Хэвлэх\", \"\")\n",
    "\n",
    "        # Navigate to the page with Selenium to check for the active tab\n",
    "        driver.get(url)\n",
    "        try:\n",
    "            WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'a[href=\"#active-tab-11\"]')))\n",
    "            # Fetch English text\n",
    "            element_eng = soup.find('div', class_='w-100 pull-left --nomigration')\n",
    "            if element_eng:\n",
    "                texts_eng = element_eng.get_text(strip=True)\n",
    "        except:\n",
    "            # Handle cases where the active tab 11 does not exist\n",
    "            texts_eng = \"not.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {url}: {str(e)}\")\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "    return {'url': url, 'title': title, 'mon': texts_mon, 'eng': texts_eng}\n",
    "\n",
    "# List of URLs to process\n",
    "\n",
    "# Use ThreadPoolExecutor to handle multiple URLs in parallel\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    results = list(executor.map(fetch_texts, all_links))\n",
    "\n",
    "# Write results to JSONL file\n",
    "with open('output3.jsonl', 'w', encoding='utf-8') as f:\n",
    "    for result in results:\n",
    "        json_line = json.dumps({\"title\": result['title'], \"mon\": result['mon'], \"eng\": result['eng']}, ensure_ascii=False)\n",
    "        f.write(json_line + '\\n')\n",
    "\n",
    "print(\"Processing complete. Data written to output.jsonl.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
